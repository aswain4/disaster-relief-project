r1
g1 <- threshold_graph(logreg_cv) + labs(title="Logistic regression model")
g1
set.seed(12345)
lda_model <- discrim_linear(mode="classification") %>%
set_engine("MASS")
lda_wf <- workflow() %>%
add_recipe(rec) %>%
add_model(lda_model) %>%
fit(haiti)
lda_cv <- fit_resamples(lda_wf, resamples, control=cv_control)
lda_metrics <- collect_metrics(lda_cv)
lda_metrics
r2 <- roc_cv_data(lda_cv) %>%
ggplot(aes(x=1-specificity, y=sensitivity)) +
geom_line() +
labs(title="LDA")
r2
g2 <- threshold_graph(lda_cv) + labs(title="LDA")
g2
set.seed(12345)
qda_model <- discrim_quad(mode="classification") %>%
set_engine("MASS")
qda_wf <- workflow() %>%
add_recipe(rec) %>%
add_model(qda_model) %>%
fit(haiti)
qda_cv <- fit_resamples(qda_wf, resamples, control=cv_control)
qda_metrics <- collect_metrics(qda_cv)
qda_metrics
r3 <- roc_cv_data(qda_cv) %>%
ggplot(aes(x=1-specificity, y=sensitivity)) +
geom_line() +
labs(title="QDA")
r3
g3 <- threshold_graph(qda_cv) + labs(title="QDA")
g3
set.seed(12345)
knn_spec <- nearest_neighbor(engine="kknn", mode="classification",
neighbors=tune())
knn_wf <- workflow() %>%
add_recipe(rec) %>%
add_model(knn_spec)
nn_params <- extract_parameter_set_dials(knn_wf) %>%
update(
neighbors=neighbors(c(2, 100))
)
tune_results_knn <- tune_grid(knn_wf,
resamples=resamples,
control=cv_control,
grid=grid_random(nn_params, size=50))
show_best(tune_results_knn, metric='roc_auc', n=5)
set.seed(12345)
autoplot(tune_results_knn) +
labs(title="Tuning KNN")
set.seed(12345)
best_params_nn <- select_best(tune_results_knn, metric='roc_auc')
best_knn_wf <- knn_wf %>%
finalize_workflow(best_params_nn) %>%
fit(haiti)
knn_cv <- fit_resamples(best_knn_wf, resamples=resamples, control=cv_control)
r4 <- roc_cv_data(knn_cv) %>%
ggplot(aes(x=1-specificity, y=sensitivity)) +
geom_line() +
labs(title="KNN")
r4
g4 <- threshold_graph(knn_cv) + labs(title="KNN model")
g4
#| warning: FALSE
#| message: FALSE
set.seed(12345)
pen_spec <- logistic_reg(engine="glmnet", mode="classification",
penalty=tune(), mixture=tune())
pen_wf <- workflow() %>%
add_recipe(rec) %>%
add_model(pen_spec)
pen_params <- extract_parameter_set_dials(pen_wf) %>%
update(
penalty=penalty(c(-5,-1)),
mixture=mixture(c(0,1))
)
pen_bayes <- tune_bayes(pen_wf,
resamples=resamples,
param_info=pen_params,
iter=50
)
autoplot(pen_bayes) +
labs(title="Tuning Penalty and Mixture")
show_best(pen_bayes, n=5)
set.seed(12345)
tuned_pen_model <- pen_wf %>%
finalize_workflow(select_best(pen_bayes, metric="roc_auc")) %>%
fit(haiti)
pen_cv <- fit_resamples(tuned_pen_model, resamples=resamples, control=cv_control)
r5 <- roc_cv_data(pen_cv) %>%
ggplot(aes(x=1-specificity, y=sensitivity)) +
geom_line() +
labs(title="Penalized logistic regression model")
r5
g5 <- threshold_graph(pen_cv) + labs(title="Penalized log reg model")
g5
#| warning: FALSE
#| message: FALSE
set.seed(12345)
random_wf <- workflow() %>%
add_recipe(rec) %>%
add_model(rand_forest(mode="classification", mtry=tune(), min_n=tune()) %>%
set_engine("ranger", importance="impurity"))
random_params <- extract_parameter_set_dials(random_wf) %>%
update(mtry=mtry(c(2,8)))
random_bayes <- tune_bayes(random_wf,
resamples=resamples,
param_info=random_params,
iter=20
)
autoplot(random_bayes) +
labs(title="Tuning Mtry and Min n")
show_best(random_bayes, n=5)
set.seed(12345)
tuned_random_model <- random_wf %>%
finalize_workflow(select_best(random_bayes, metric="roc_auc")) %>%
fit(haiti)
random_cv <- fit_resamples(tuned_random_model, resamples=resamples, control=cv_control)
r6 <- roc_cv_data(random_cv) %>%
ggplot(aes(x=1-specificity, y=sensitivity)) +
geom_line() +
labs(title="Random Forest model")
r6
g6 <- threshold_graph(random_cv) + labs(title="Random Forest model")
g6
#| warning: FALSE
set.seed(12345)
svml_wf <- workflow() %>%
add_recipe(rec) %>%
add_model(svm_linear(engine="kernlab", mode="classification",
cost=tune(), margin=tune()))
svml_params <- extract_parameter_set_dials(svml_wf)
svml_bayes <- tune_bayes(svml_wf,
resamples=resamples,
param_info=svml_params,
iter=25
)
autoplot(svml_bayes) +
labs(title="Tuning Cost and Margin")
show_best(svml_bayes, n=5)
set.seed(12345)
tuned_svml_model <- svml_wf %>%
finalize_workflow(select_best(svml_bayes, metric="roc_auc")) %>%
fit(haiti)
svml_cv <- fit_resamples(tuned_svml_model, resamples=resamples, control=cv_control)
r7 <- roc_cv_data(svml_cv) %>%
ggplot(aes(x=1-specificity, y=sensitivity)) +
geom_line() +
labs(title="SVM-Linear model")
r7
g7 <- threshold_graph(svml_cv) + labs(title="SVM-Linear model")
g7
#| warning: FALSE
#| message: FALSE
set.seed(12345)
svmp_wf <- workflow() %>%
add_recipe(rec) %>%
add_model(svm_poly(engine="kernlab", mode="classification",
cost=tune(), margin=tune(), degree=tune()))
svmp_params <- extract_parameter_set_dials(svmp_wf)
svmp_bayes <- tune_bayes(svmp_wf,
resamples=resamples,
param_info=svmp_params,
iter=25
)
autoplot(svmp_bayes) +
labs(title="Tuning Cost, Margin, and Degree")
show_best(svmp_bayes, n=5)
set.seed(12345)
tuned_svmp_model <- svmp_wf %>%
finalize_workflow(select_best(svmp_bayes, metric="roc_auc")) %>%
fit(haiti)
svmp_cv <- fit_resamples(tuned_svmp_model, resamples=resamples, control=cv_control)
r8 <- roc_cv_data(svmp_cv) %>%
ggplot(aes(x=1-specificity, y=sensitivity)) +
geom_line() +
labs(title="SVM-Polynomial model")
r8
g8 <- threshold_graph(svmp_cv) + labs(title="SVM-Polynomial model")
g8
#| warning: FALSE
#| message: FALSE
set.seed(12345)
rbf_wf <- workflow() %>%
add_recipe(rec) %>%
add_model(svm_rbf(engine="kernlab", mode="classification",
cost=tune(), margin=tune(), rbf_sigma=tune()))
rbf_params <- extract_parameter_set_dials(rbf_wf) %>%
update(rbf_sigma= rbf_sigma(range=c(-4, 0), trans=log10_trans()))
rbf_bayes <- tune_bayes(rbf_wf,
resamples=resamples,
param_info=rbf_params,
iter=25
)
autoplot(rbf_bayes) +
labs(title="Tuning Cost, Margin, and Sigma")
show_best(rbf_bayes, n=5)
set.seed(12345)
tuned_rbf_model <- rbf_wf %>%
finalize_workflow(select_best(rbf_bayes, metric="roc_auc")) %>%
fit(haiti)
rbf_cv <- fit_resamples(tuned_rbf_model, resamples=resamples, control=cv_control)
r9 <- roc_cv_data(rbf_cv) %>%
ggplot(aes(x=1-specificity, y=sensitivity)) +
geom_line() +
labs(title="SVM-Radial Basis Function model")
r9
g9 <- threshold_graph(rbf_cv) + labs(title="SVM-Radial Basis Function model")
g9
thresholds <- function(model) {
performance <- probably::threshold_perf(
model %>% collect_predictions(),
Blue_Tarp, .pred_Yes,
thresholds=seq(0.05, 0.9, 0.01), event_level="second",
metrics=metric_set(accuracy, sensitivity, specificity, j_index, precision)
)
max_j_index <- performance %>%
filter(.metric == "j_index") %>%
filter(.estimate == max(.estimate))
max_values <- performance %>%
filter(.threshold %in% max_j_index$.threshold)
return (max_values)
}
threshold_stats <- function(model) {
# get best threshold
thresh <- thresholds(model) %>% filter(.metric == 'j_index') %>% data.frame() %>% select(.threshold)
# calc stats
performance <- probably::threshold_perf(
model %>% collect_predictions(),
Blue_Tarp, .pred_Yes,
thresholds=thresh, event_level="second",
metrics=metric_set(j_index, accuracy, precision, sensitivity, specificity))
# pivot to add FPR
thresh_stats <- pivot_wider(performance, id_cols=.threshold, names_from=.metric,
values_from=.estimate) %>% mutate(FPR = 1 - specificity)
return (thresh_stats)
}
knitr::kable(
bind_rows(
threshold_stats(logreg_cv) %>% mutate(model='Logistic Regression'),
threshold_stats(lda_cv) %>% mutate(model='LDA'),
threshold_stats(qda_cv) %>% mutate(model='QDA'),
threshold_stats(knn_cv)%>% mutate(model='KNN'),
threshold_stats(pen_cv)%>% mutate(model='Penalized Log Reg'),
threshold_stats(random_cv) %>% mutate(model='Random Forest'),
threshold_stats(svml_cv) %>% mutate(model="SVM Linear"),
threshold_stats(svmp_cv) %>% mutate(model="SVM Polynomial"),
threshold_stats(rbf_cv) %>% mutate(model="Radial Basis Function")
),
caption = 'Cross Validation Metrics at Selected Threshold'
) %>% kableExtra::kable_styling(full_width=FALSE)
roc_cv_data <- function(model_cv) {
cv_predictions <- collect_predictions(model_cv)
cv_predictions %>%
roc_curve(truth=Blue_Tarp, .pred_Yes, event_level="second")
}
bind_rows(
roc_cv_data(logreg_cv) %>% mutate(model="Logistic regression"),
roc_cv_data(lda_cv) %>% mutate(model="LDA"),
roc_cv_data(qda_cv) %>% mutate(model="QDA"),
roc_cv_data(knn_cv) %>% mutate(model="KNN"),
roc_cv_data(pen_cv) %>% mutate(model="Penalized Logistic regression"),
roc_cv_data(random_cv) %>% mutate(model="Random Forest"),
roc_cv_data(svml_cv) %>% mutate(model="SVM Linear"),
roc_cv_data(svmp_cv) %>% mutate(model="SVM Polynomial"),
roc_cv_data(rbf_cv) %>% mutate(model="Radial Basis Function")
) %>%
ggplot(aes(x=1-specificity, y=sensitivity, color=model)) +
geom_line() +
labs(title="ROC Curves of All Models") +
coord_cartesian(xlim=c(0, 0.25), ylim=c(0.75, 1))
#| message: FALSE
columns <- c('ID', 'X', 'Y', 'Map X', 'Map Y', 'Lat', 'Lon', 'B1', 'B2', 'B3')
tarps67 <- read_table("HoldOutData/orthovnir067_ROI_Blue_Tarps.txt", col_names=columns, skip=8) %>%
mutate(Blue_Tarp = "Yes")
tarps69 <- read_table("HoldOutData/orthovnir069_ROI_Blue_Tarps.txt", col_names=columns, skip=8) %>%
mutate(Blue_Tarp = "Yes")
tarps78 <- read_table("HoldOutData/orthovnir078_ROI_Blue_Tarps.txt", col_names=columns, skip=8) %>%
mutate(Blue_Tarp = "Yes")
non67 <- read_table("HoldOutData/orthovnir067_ROI_NOT_Blue_Tarps.txt", col_names=columns, skip=8) %>%
mutate(Blue_Tarp = "No")
non69 <- read_table("HoldOutData/orthovnir069_ROI_NOT_Blue_Tarps.txt", col_names=columns, skip=8) %>%
mutate(Blue_Tarp = "No")
non78 <- read_table("HoldOutData/orthovnir078_ROI_NON_Blue_Tarps.txt", col_names=columns, skip=8) %>%
mutate(Blue_Tarp = "No")
non57 <- read_table("HoldOutData/orthovnir057_ROI_NON_Blue_Tarps.txt", col_names=columns, skip=8) %>%
mutate(Blue_Tarp = "No")
test <- bind_rows(tarps67, tarps69, tarps78, non57, non67, non69, non78) %>%
mutate(Blue_Tarp = factor(Blue_Tarp)) %>%
select(Lat, Lon, B1, B2, B3, Blue_Tarp) %>%
rename(Red=B1, Green=B2, Blue=B3)
logreg_ho <- predict(logreg_wf, new_data=test) %>%
bind_cols(test)
lda_ho <- predict(lda_wf, new_data=test) %>%
bind_cols(test)
qda_ho <- predict(qda_wf, new_data=test) %>%
bind_cols(test)
knn_ho <- predict(best_knn_wf, new_data=test) %>%
bind_cols(test)
pen_ho <- predict(tuned_pen_model, new_data=test) %>%
bind_cols(test)
random_ho <- predict(tuned_random_model, new_data = test) %>%
bind_cols(test)
svml_ho <- predict(tuned_svml_model, new_data=test) %>%
bind_cols(test)
svmp_ho <- predict(tuned_svmp_model, new_data=test) %>%
bind_cols(test)
rbf_ho <- predict(tuned_rbf_model, new_data=test) %>%
bind_cols(test)
holdout_stats <- function(ho_model, train_model) {
# get best threshold
thresh <- thresholds(train_model) %>% filter(.metric == 'j_index') %>% data.frame() %>% select(.threshold)
# calc stats
ho_model$.pred_class <- as.numeric(ho_model$.pred_class == "Yes")
performance <- probably::threshold_perf(
ho_model, truth=Blue_Tarp, estimate=.pred_class,
thresholds=thresh, event_level="second",
metrics=metric_set(j_index, accuracy, precision, sensitivity, specificity))
# pivot to add FPR
thresh_stats <- pivot_wider(performance, id_cols=.threshold, names_from=.metric,
values_from=.estimate) %>% mutate(FPR = 1 - specificity)
return (thresh_stats)
}
knitr::kable(
bind_rows(
holdout_stats(logreg_ho, logreg_cv) %>% mutate(model='Logistic Regression'),
holdout_stats(lda_ho, lda_cv) %>% mutate(model='LDA'),
holdout_stats(qda_ho, qda_cv) %>% mutate(model='QDA'),
holdout_stats(knn_ho, knn_cv)%>% mutate(model='KNN'),
holdout_stats(pen_ho, pen_cv)%>% mutate(model='Penalized Log Reg'),
holdout_stats(random_ho, random_cv) %>% mutate(model='Random Forest'),
holdout_stats(svml_ho, svml_cv) %>% mutate(model="SVM Linear"),
holdout_stats(svmp_ho, svmp_cv) %>% mutate(model="SVM Polynomial"),
holdout_stats(rbf_ho, rbf_cv) %>% mutate(model="Radial Basis Function")
),
caption = 'Holdout Metrics at Selected Threshold'
) %>% kableExtra::kable_styling(full_width=FALSE)
holdout_stats <- function(model, data, model_name, threshold) {
model %>%
augment(data) %>%
probably::threshold_perf(Blue_Tarp, .pred_Yes,
thresholds=threshold, event_level="second",
metrics=metric_set(j_index, sensitivity, specificity, accuracy, precision)) %>%
mutate(model=model_name)
}
knitr::kable(
bind_rows(
holdout_stats(logreg_wf, test, "Logistic Regression", 0.05),
holdout_stats(lda_wf, test, "LDA", 0.05),
holdout_stats(qda_wf, test, "QDA", 0.05),
holdout_stats(best_knn_wf, test, "KNN", 0.08),
holdout_stats(tuned_pen_model, test, "Penalized Log Reg", 0.05),
holdout_stats(tuned_random_model, test, "Random Forest", 0.07),
holdout_stats(tuned_svml_model, test, "SVM Linear", 0.05),
holdout_stats(tuned_svmp_model, test, "SVM Polynomial", 0.05),
holdout_stats(tuned_rbf_model, test, "Radial Basis Function", 0.05)
),
caption = 'Holdout Metrics at Selected Threshold', digits=3
) %>% kableExtra::kable_styling(full_width=FALSE)
#| warning: FALSE
vegetation <- haiti %>%
filter(Class == 'Vegetation') %>%
ggplot(aes(x=Green)) +
geom_density(color='green') +
geom_density(aes(x=Red), color='red') +
geom_density(aes(x=Blue), color='blue') +
labs(x='Pixel Value', y='Density', title="Vegetation") +
scale_x_continuous(limits = c(0, 255))
rooftop <- haiti %>%
filter(Class == 'Rooftop') %>%
ggplot(aes(x=Red)) +
geom_density(color='red') +
geom_density(aes(x=Green), color='green') +
geom_density(aes(x=Blue), color='blue') +
labs(x='Pixel Value', y='Density', title="Rooftop") +
scale_x_continuous(limits = c(0, 255))
soil <- haiti %>%
filter(Class == 'Soil') %>%
ggplot(aes(x=Red)) +
geom_density(color='red') +
geom_density(aes(x=Green), color='green') +
geom_density(aes(x=Blue), color='blue') +
labs(x='Pixel Value', y='Density', title="Soil") +
scale_x_continuous(limits = c(0, 255))
tarped <- haiti %>%
filter(Class == 'Blue Tarp') %>%
ggplot(aes(x=Blue)) +
geom_density(color='blue') +
geom_density(aes(x=Red), color='red') +
geom_density(aes(x=Green), color='green') +
labs(x='Pixel Value', y='Density', title="Blue Tarp") +
scale_x_continuous(limits = c(0, 255))
various <- haiti %>%
filter(Class == 'Various Non-Tarp') %>%
ggplot(aes(x=Blue)) +
geom_density(color='blue') +
geom_density(aes(x=Red), color='red') +
geom_density(aes(x=Green), color='green') +
labs(x='Pixel Value', y='Density', title="Various Non-Tarp") +
scale_x_continuous(limits = c(0, 255))
(tarped + soil + vegetation) / (rooftop + various)
#| warning: FALSE
vegetation <- haiti %>%
filter(Class == 'Vegetation') %>%
ggplot(aes(x=Green)) +
geom_density(color='green') +
geom_density(aes(x=Red), color='red') +
geom_density(aes(x=Blue), color='blue') +
labs(x='Pixel Value', y='Density', title="Vegetation") +
scale_x_continuous(limits = c(0, 255))
rooftop <- haiti %>%
filter(Class == 'Rooftop') %>%
ggplot(aes(x=Red)) +
geom_density(color='red') +
geom_density(aes(x=Green), color='green') +
geom_density(aes(x=Blue), color='blue') +
labs(x='Pixel Value', y='Density', title="Rooftop") +
scale_x_continuous(limits = c(0, 255))
soil <- haiti %>%
filter(Class == 'Soil') %>%
ggplot(aes(x=Red)) +
geom_density(color='red') +
geom_density(aes(x=Green), color='green') +
geom_density(aes(x=Blue), color='blue') +
labs(x='Pixel Value', y='Density', title="Soil") +
scale_x_continuous(limits = c(0, 255))
tarped <- haiti %>%
filter(Class == 'Blue Tarp') %>%
ggplot(aes(x=Blue)) +
geom_density(color='blue') +
geom_density(aes(x=Red), color='red') +
geom_density(aes(x=Green), color='green') +
labs(x='Pixel Value', y='Density', title="Blue Tarp") +
scale_x_continuous(limits = c(0, 255))
various <- haiti %>%
filter(Class == 'Various Non-Tarp') %>%
ggplot(aes(x=Blue)) +
geom_density(color='blue') +
geom_density(aes(x=Red), color='red') +
geom_density(aes(x=Green), color='green') +
labs(x='Pixel Value', y='Density', title="Various Non-Tarp") +
scale_x_continuous(limits = c(0, 255))
(tarped + soil + vegetation) / (rooftop + various)
thresholds <- function(model) {
performance <- probably::threshold_perf(
model %>% collect_predictions(),
Blue_Tarp, .pred_Yes,
thresholds=seq(0.05, 0.9, 0.01), event_level="second",
metrics=metric_set(accuracy, sensitivity, specificity, j_index, precision)
)
max_j_index <- performance %>%
filter(.metric == "j_index") %>%
filter(.estimate == max(.estimate))
max_values <- performance %>%
filter(.threshold %in% max_j_index$.threshold)
return (max_values)
}
threshold_stats <- function(model) {
# get best threshold
thresh <- thresholds(model) %>% filter(.metric == 'j_index') %>% data.frame() %>% select(.threshold)
# calc stats
performance <- probably::threshold_perf(
model %>% collect_predictions(),
Blue_Tarp, .pred_Yes,
thresholds=thresh, event_level="second",
metrics=metric_set(j_index, accuracy, precision, sensitivity, specificity))
# pivot to add FPR
thresh_stats <- pivot_wider(performance, id_cols=.threshold, names_from=.metric,
values_from=.estimate) %>% mutate(FPR = 1 - specificity)
return (thresh_stats)
}
knitr::kable(
bind_rows(
threshold_stats(logreg_cv) %>% mutate(model='Logistic Regression'),
threshold_stats(lda_cv) %>% mutate(model='LDA'),
threshold_stats(qda_cv) %>% mutate(model='QDA'),
threshold_stats(knn_cv)%>% mutate(model='KNN'),
threshold_stats(pen_cv)%>% mutate(model='Penalized Log Reg'),
threshold_stats(random_cv) %>% mutate(model='Random Forest'),
threshold_stats(svml_cv) %>% mutate(model="SVM Linear"),
threshold_stats(svmp_cv) %>% mutate(model="SVM Polynomial"),
threshold_stats(rbf_cv) %>% mutate(model="Radial Basis Function")
),
caption = 'Cross Validation Metrics at Selected Threshold', digits=3
) %>% kableExtra::kable_styling(full_width=FALSE)
holdout_stats <- function(model, data, model_name, threshold) {
model %>%
augment(data) %>%
probably::threshold_perf(Blue_Tarp, .pred_Yes,
thresholds=threshold, event_level="second",
metrics=metric_set(j_index, sensitivity, specificity, accuracy, precision)) %>%
mutate(model=model_name)
}
knitr::kable(
bind_rows(
holdout_stats(logreg_wf, test, "Logistic Regression", 0.05),
holdout_stats(lda_wf, test, "LDA", 0.05),
holdout_stats(qda_wf, test, "QDA", 0.05),
holdout_stats(best_knn_wf, test, "KNN", 0.08),
holdout_stats(tuned_pen_model, test, "Penalized Log Reg", 0.05),
holdout_stats(tuned_random_model, test, "Random Forest", 0.07),
holdout_stats(tuned_svml_model, test, "SVM Linear", 0.05),
holdout_stats(tuned_svmp_model, test, "SVM Polynomial", 0.05),
holdout_stats(tuned_rbf_model, test, "Radial Basis Function", 0.05)
),
caption = 'Holdout Metrics at Selected Threshold', digits=3
) %>% kableExtra::kable_styling(full_width=FALSE)
